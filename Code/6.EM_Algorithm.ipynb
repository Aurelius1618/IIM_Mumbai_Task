{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----------------------FILEPATHS----------------------###\n",
    "primary_facility_path = '../Data/Primary_Facility_50.csv'\n",
    "secondary_facility_path = '../Data/Secondary_Facility_500.csv'\n",
    "\n",
    "supplier_path = '../Data/Supplier.csv'\n",
    "# result_path = '../Results/Agglomerative_clustering_rq_200.pkl'\n",
    "\n",
    "result_path = '../Results/Agglomerative_clustering_rq_50.pkl'\n",
    "\n",
    "customer_path = '../Results/50_customer_coordinates.npy'\n",
    "# customer_path = '../Results/200_customer_coordinates.npy'\n",
    "\n",
    "\n",
    "###----------------------PARAMETERS----------------------###\n",
    "RP = 5\n",
    "seed = 100\n",
    "counter = 0\n",
    "C_SUPPLIER = 0.0006\n",
    "C_PRIMARY = 0.0024\n",
    "C_CUSTOMER = 0.012\n",
    "MAX_ITERATIONS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----------------------READ ALL INPUT DATAFILES----------------------###\n",
    "p_df = pd.read_csv(primary_facility_path)\n",
    "q_df = pd.read_csv(secondary_facility_path)\n",
    "s_df = pd.read_csv(supplier_path)\n",
    "with open(result_path, 'rb') as f:\n",
    "    vq_k_dict = pickle.load(f)\n",
    "\n",
    "k_coordinates = np.load(customer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----------------------DIJKSTRA'S ALGORITHM FOR E-STEP : TO FIND SHORTEST PATHS BETWEEN SUPPLIER TO PRIMARY FACILITY TO SECONDARY FACILITIES----------------------###\n",
    "def expectation_algorithm(graph, starts):\n",
    "    shortest_path = {node: float('infinity') for node in graph}\n",
    "    prev = {node: None for node in graph}\n",
    "    priority_queue = []\n",
    "\n",
    "    ###----------------------INITIALIZE ALL POINTS WITH A DISTANCE = 0----------------------###\n",
    "    for start in starts:\n",
    "        shortest_path[start] = 0\n",
    "        heapq.heappush(priority_queue, (0, start))\n",
    "\n",
    "    while priority_queue:\n",
    "        current_distance, current_node = heapq.heappop(priority_queue)\n",
    "\n",
    "        if current_distance > shortest_path[current_node]:\n",
    "            continue\n",
    "\n",
    "        for neighbor, weight in graph[current_node].items():\n",
    "            distance = current_distance + weight\n",
    "\n",
    "            if distance < shortest_path[neighbor]:\n",
    "                shortest_path[neighbor] = distance\n",
    "                prev[neighbor] = current_node  # FOR PATH RE-CONSTRUCTION\n",
    "                heapq.heappush(priority_queue, (distance, neighbor))\n",
    "\n",
    "    return shortest_path, prev\n",
    "\n",
    "def reconstruct_path(source, target, prev):\n",
    "    path = [target]\n",
    "    while target in prev and prev[target] is not None:\n",
    "        target = prev[target]\n",
    "        path.append(target)\n",
    "    path.reverse()\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_to_customers_idx = []\n",
    "secondary_facilities_idx = []\n",
    "\n",
    "for Q, K in vq_k_dict.items():\n",
    "    q_idx = int(Q.split('_')[1])\n",
    "    k_idx = int(K.split('_')[1])\n",
    "    secondary_to_customers_idx.append([q_idx, k_idx])   # LOAD SECONDARY FACILITIES TO CUSTOMER COMPUTED FROM AGGLOMERATIVE CLUSTERING\n",
    "    secondary_facilities_idx.append(q_idx)  # LOAD SECONDARY FACILITIY INDICES\n",
    "\n",
    "p_df_sampled = p_df.sample(RP, random_state=seed)   # RANDOMLY SAMPLING INITIAL PRIMARY FACILITIES WITH A DEFINED SEED\n",
    "primary_facilities_idx = list(p_df_sampled.index)   # LOAD INITIAL PRIMARY FACILITY INDICES\n",
    "supplier_facilties_idx = list(s_df.index)   # LOAD SUPPLIER INDICES\n",
    "\n",
    "all_primary_facilities_dict = dict(zip([p for p in list(p_df.index)], p_df[['Latitude', 'Longitude']].values))  # PRIMARY FACILTY SET {INDEX : COORDINATES}\n",
    "\n",
    "updated_primary_list = []   # INITIALIZE THE PRIMARY FACILITY INDEX LIST TO BE UPDATED IN E-M STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL RANDOM PRIMARY FACILITIES :  [6, 36, 37, 28, 43]\n",
      "COUNTER : 1\n",
      "CURRENT BEST PRIMARY FACILITIES : [17, 20, 28, 14, 8]\n",
      "COUNTER : 2\n",
      "CURRENT BEST PRIMARY FACILITIES : [20, 14, 17, 41, 23]\n",
      "FINAL BEST PRIMARY FACILITIES : [20, 14, 17, 41, 23]\n",
      "Shortest path to Q_65: ['S_0', 'P_23', 'Q_65'] and cost : 0.03491389764381461\n",
      "Shortest path to Q_440: ['S_0', 'P_23', 'Q_440'] and cost : 0.10118775038956254\n",
      "Shortest path to Q_338: ['S_0', 'P_17', 'Q_338'] and cost : 0.03715485067035948\n",
      "Shortest path to Q_51: ['S_0', 'P_23', 'Q_51'] and cost : 0.030414069229470396\n",
      "Shortest path to Q_161: ['S_0', 'P_17', 'Q_161'] and cost : 0.025044425244849643\n",
      "Shortest path to Q_317: ['S_0', 'P_17', 'Q_317'] and cost : 0.021599521921081256\n",
      "Shortest path to Q_50: ['S_0', 'P_20', 'Q_50'] and cost : 0.027558324626371457\n",
      "Shortest path to Q_237: ['S_0', 'P_41', 'Q_237'] and cost : 0.055431845813842126\n",
      "Shortest path to Q_31: ['S_0', 'P_23', 'Q_31'] and cost : 0.10541439852959403\n",
      "Shortest path to Q_332: ['S_0', 'P_17', 'Q_332'] and cost : 0.017992637349367874\n",
      "Shortest path to Q_126: ['S_0', 'P_23', 'Q_126'] and cost : 0.0688759109145052\n",
      "Shortest path to Q_385: ['S_0', 'P_41', 'Q_385'] and cost : 0.055649928121693754\n",
      "Shortest path to Q_435: ['S_0', 'P_17', 'Q_435'] and cost : 0.030170648326721866\n",
      "Shortest path to Q_12: ['S_0', 'P_41', 'Q_12'] and cost : 0.04469360717761234\n",
      "Shortest path to Q_143: ['S_0', 'P_41', 'Q_143'] and cost : 0.04574429946736267\n",
      "Shortest path to Q_287: ['S_0', 'P_17', 'Q_287'] and cost : 0.03678079063975863\n",
      "Shortest path to Q_89: ['S_0', 'P_17', 'Q_89'] and cost : 0.022791873042111492\n",
      "Shortest path to Q_80: ['S_0', 'P_17', 'Q_80'] and cost : 0.061110712104387635\n",
      "Shortest path to Q_348: ['S_0', 'P_20', 'Q_348'] and cost : 0.026450121074816417\n",
      "Shortest path to Q_397: ['S_0', 'P_41', 'Q_397'] and cost : 0.035014908540917176\n",
      "Shortest path to Q_45: ['S_0', 'P_17', 'Q_45'] and cost : 0.017007531352909513\n",
      "Shortest path to Q_445: ['S_0', 'P_17', 'Q_445'] and cost : 0.02915160566626198\n",
      "Shortest path to Q_113: ['S_0', 'P_41', 'Q_113'] and cost : 0.033685667758905635\n",
      "Shortest path to Q_319: ['S_0', 'P_17', 'Q_319'] and cost : 0.024094331117452503\n",
      "Shortest path to Q_241: ['S_0', 'P_17', 'Q_241'] and cost : 0.030828772864284978\n",
      "Shortest path to Q_400: ['S_0', 'P_23', 'Q_400'] and cost : 0.06864580825609352\n",
      "Shortest path to Q_450: ['S_0', 'P_17', 'Q_450'] and cost : 0.06082939664469701\n",
      "Shortest path to Q_223: ['S_0', 'P_41', 'Q_223'] and cost : 0.05358582230880565\n",
      "Shortest path to Q_189: ['S_0', 'P_17', 'Q_189'] and cost : 0.030529038832466472\n",
      "Shortest path to Q_178: ['S_0', 'P_23', 'Q_178'] and cost : 0.03536341212160651\n",
      "Shortest path to Q_247: ['S_0', 'P_41', 'Q_247'] and cost : 0.05730375384396358\n",
      "Shortest path to Q_378: ['S_0', 'P_23', 'Q_378'] and cost : 0.06949750904840292\n",
      "Shortest path to Q_454: ['S_0', 'P_23', 'Q_454'] and cost : 0.109588531764268\n",
      "Shortest path to Q_281: ['S_0', 'P_23', 'Q_281'] and cost : 0.03492089888540438\n",
      "Shortest path to Q_314: ['S_0', 'P_23', 'Q_314'] and cost : 0.030230246547219123\n",
      "Shortest path to Q_121: ['S_0', 'P_23', 'Q_121'] and cost : 0.03565382780418357\n",
      "Shortest path to Q_171: ['S_0', 'P_17', 'Q_171'] and cost : 0.037672248649264495\n",
      "Shortest path to Q_174: ['S_0', 'P_20', 'Q_174'] and cost : 0.029573115552919686\n",
      "Shortest path to Q_225: ['S_0', 'P_23', 'Q_225'] and cost : 0.022748704410649086\n",
      "Shortest path to Q_211: ['S_0', 'P_23', 'Q_211'] and cost : 0.10677503628394155\n",
      "Shortest path to Q_268: ['S_0', 'P_17', 'Q_268'] and cost : 0.0255310971381532\n",
      "Shortest path to Q_100: ['S_0', 'P_17', 'Q_100'] and cost : 0.035752243337442785\n",
      "Shortest path to Q_491: ['S_0', 'P_23', 'Q_491'] and cost : 0.03633344221867191\n",
      "Shortest path to Q_459: ['S_0', 'P_20', 'Q_459'] and cost : 0.045705460628406164\n",
      "Shortest path to Q_263: ['S_0', 'P_41', 'Q_263'] and cost : 0.03261086621961408\n",
      "Shortest path to Q_77: ['S_0', 'P_23', 'Q_77'] and cost : 0.06637411538407648\n",
      "Shortest path to Q_330: ['S_0', 'P_17', 'Q_330'] and cost : 0.02909917113319309\n",
      "Shortest path to Q_484: ['S_0', 'P_23', 'Q_484'] and cost : 0.02816273656564402\n",
      "Shortest path to Q_381: ['S_0', 'P_17', 'Q_381'] and cost : 0.031885166842817725\n",
      "Shortest path to Q_182: ['S_0', 'P_23', 'Q_182'] and cost : 0.06576652347085538\n"
     ]
    }
   ],
   "source": [
    "###----------------------ITERATIVELY SOLVING E-M ALGORITHM----------------------###\n",
    "print(f'INITIAL RANDOM PRIMARY FACILITIES : ', list(p_df_sampled.index))\n",
    "while counter < MAX_ITERATIONS:\n",
    "\n",
    "    ###----------------------DEFINE GRAPH----------------------###\n",
    "    graph = {}\n",
    "\n",
    "    ###----------------------SUPPLIER TO PRIMARY----------------------###\n",
    "    for s in s_df['Index']:\n",
    "        graph[f'S_{s}'] = {}\n",
    "        for p in primary_facilities_idx:\n",
    "            src = s_df.loc[s][['Latitude', 'Longitude']].values\n",
    "            dest = all_primary_facilities_dict[p]\n",
    "            graph[f'S_{s}'][f'P_{p}'] = np.linalg.norm(src - dest) * C_SUPPLIER\n",
    "\n",
    "    ###----------------------PRIMARY TO SECONDARY----------------------###\n",
    "    for p in primary_facilities_idx:\n",
    "        graph[f'P_{p}'] = {}\n",
    "        for q in secondary_facilities_idx:\n",
    "            src = all_primary_facilities_dict[p]\n",
    "            dest = q_df.loc[q][['Latitude', 'Longitude']].values\n",
    "            graph[f'P_{p}'][f'Q_{q}'] = np.linalg.norm(src - dest) * C_PRIMARY\n",
    "\n",
    "    ## REMARK : We assume Secondary facilities as the destination nodes that are must to be fulfilled from Supplier\n",
    "    for q in secondary_facilities_idx:\n",
    "        graph[f'Q_{q}'] = {}\n",
    "\n",
    "    src = f'S_{supplier_facilties_idx[0]}'\n",
    "\n",
    "    ###----------------------E-STEP----------------------###\n",
    "    shortest_distances, previous_vertices = expectation_algorithm(graph, [f'S_{s}' for s in s_df['Index']])\n",
    "    all_shortest_paths = {q: reconstruct_path(src, q, previous_vertices) for q in [f'Q_{i}' for i in secondary_facilities_idx]}\n",
    "\n",
    "    ###----------------------INITIALIZATION OF X, Y, T FLOWS----------------------###\n",
    "    x_flows = {}  # x_{si} flows\n",
    "    y_flows = {}  # y_{ij} flows\n",
    "    tau_flows = {}  # t_{ii'} flows}\n",
    "\n",
    "    for sec_facility, path in all_shortest_paths.items():\n",
    "        ###----------------------EXTRACT SUPPLIER, PRIMARY AND SECONDARY PATHS FROM SHORTEST PATHS COMPUTED IN E-STEP----------------------###\n",
    "        supplier, primary, secondary = path\n",
    "        ###----------------------COMPUTE Xsp_FLOW----------------------###\n",
    "        x_flows_key = (supplier, primary)\n",
    "        if x_flows_key in x_flows:\n",
    "            x_flows[x_flows_key] += 1\n",
    "        else:\n",
    "            x_flows[x_flows_key] = 1\n",
    "\n",
    "        ###----------------------COMPUTE Ypq_FLOW----------------------###\n",
    "        y_flows_key = (primary, secondary)\n",
    "        if y_flows_key in y_flows:\n",
    "            y_flows[y_flows_key] += 1\n",
    "        else:\n",
    "            y_flows[y_flows_key] = 1\n",
    "\n",
    "    ###----------------------DETERMINE T_FLOW USING NEAREST NEIGHBORS TO PRIMARY FACILITIES----------------------###\n",
    "    nearest_neighbors = {}\n",
    "    for p1 in all_primary_facilities_dict.keys():\n",
    "        closest_p = None\n",
    "        closest_distance = float('inf')\n",
    "        for p2 in all_primary_facilities_dict.keys():\n",
    "            if p1 != p2:\n",
    "                distance = np.linalg.norm(all_primary_facilities_dict[p1] - all_primary_facilities_dict[p2])\n",
    "                if distance < closest_distance:\n",
    "                    closest_distance = distance\n",
    "                    closest_p = p2\n",
    "        nearest_neighbors[p1] = closest_p\n",
    "\n",
    "    ###----------------------COMPUTE Tpp'_FLOW----------------------###\n",
    "\n",
    "    for primary, neighbor in nearest_neighbors.items():\n",
    "        for secondary, flow in y_flows.items():\n",
    "            if secondary[0] == primary:\n",
    "                key = (primary, neighbor)\n",
    "                if key in tau_flows:\n",
    "                    tau_flows[key] += flow\n",
    "                else:\n",
    "                    tau_flows[key] = flow\n",
    "    \n",
    "    ###--------------------------------------------------###\n",
    "    ###----------------------M-STEP----------------------###\n",
    "    ###--------------------------------------------------###\n",
    "\n",
    "    ###----------------------INITIALIZE T, A, B MATRIX FOR OPTIMAL COORDINATES COMPUTATION----------------------###\n",
    "    T = np.zeros((RP, RP))\n",
    "    A = np.zeros(RP)\n",
    "    B = np.zeros(RP)\n",
    "    # print(T)\n",
    "\n",
    "    ###----------------------COMPUTE T-MATRIX----------------------###\n",
    "    for p in range(RP):\n",
    "        for p_ in range(RP):\n",
    "            if p == p_:\n",
    "                ###----------------------COMPUTE DIAGONAL ELEMENTS IN T-MATRIX----------------------###\n",
    "                ###----------------------REMARK : ADDED THE 1e-10 TERM TO ENSURE THAT T_inv ALWAYS EXIST \n",
    "                T[p][p_] = 1e-10 + (C_SUPPLIER * sum(x_flows.get((f'S_{s}', f'P_{primary_facilities_idx[p]}'), 0) for s in supplier_facilties_idx)\n",
    "                        + C_PRIMARY * sum(tau_flows.get((f'P_{primary_facilities_idx[p]}', f'P_{primary_facilities_idx[p_prime]}'), 0) + tau_flows.get((f'P_{primary_facilities_idx[p_prime]}', f'P_{primary_facilities_idx[p]}'), 0) for p_prime in range(RP) if p_prime != p)\n",
    "                        + C_PRIMARY * sum(y_flows.get((f'P_{primary_facilities_idx[p]}', f'Q_{q}'), 0) for q in secondary_facilities_idx))\n",
    "                # print(T)\n",
    "            else:\n",
    "                ###----------------------COMPUTE OFF-DIAGONAL T-MATRIX----------------------###\n",
    "                T[p][p_] = -C_PRIMARY * (tau_flows.get((f'P_{primary_facilities_idx[p]}', f'P_{primary_facilities_idx[p_]}'), 0) + tau_flows.get((f'P_{primary_facilities_idx[p_]}', f'P_{primary_facilities_idx[p]}'), 0))\n",
    "                # print(T)\n",
    "    ###----------------------COMPUTE A AND B VECTORS----------------------###\n",
    "    for p in range(RP):\n",
    "        A[p] = C_SUPPLIER * sum(x_flows.get((s, f'P_{primary_facilities_idx[p]}'), 0) * s_df.loc[s]['Latitude'] for s in supplier_facilties_idx) + C_PRIMARY * sum(y_flows.get((f'P_{primary_facilities_idx[p]}', f'Q_{q}'), 0) * q_df.loc[q]['Latitude'] for q in secondary_facilities_idx)\n",
    "        B[p] = C_SUPPLIER * sum(x_flows.get((s, f'P_{primary_facilities_idx[p]}'), 0) * s_df.loc[s]['Longitude'] for s in supplier_facilties_idx) + C_PRIMARY * sum(y_flows.get((f'P_{primary_facilities_idx[p]}', f'Q_{q}'), 0) * q_df.loc[q]['Longitude'] for q in secondary_facilities_idx)\n",
    "\n",
    "    ###----------------------COMPUTE OPTIMAL PRIMARY FACILITY COORDINATES----------------------###\n",
    "    T_inv = np.linalg.inv(T)\n",
    "    calculated_coords = {}\n",
    "    for p in range(RP):\n",
    "        calculated_coords[f'P_{primary_facilities_idx[p]}'] = (np.dot(T_inv[p], A), np.dot(T_inv[p], B))\n",
    "    \n",
    "    ###----------------------COMPUTE NEAREST PRIMARY FACILITY FROM THE OPTIMAL COORDINATES----------------------###\n",
    "    for coords in calculated_coords.values():\n",
    "        nearest_dist = float('infinity')\n",
    "        for p_idx, p_coords in all_primary_facilities_dict.items():\n",
    "            dist = np.linalg.norm(coords - p_coords)\n",
    "            if dist < nearest_dist and p_idx not in set(updated_primary_list):\n",
    "                nearest_dist = dist\n",
    "                nearest_coords = p_coords\n",
    "                nearest_idx = p_idx\n",
    "        updated_primary_list.append(nearest_idx)\n",
    "\n",
    "    ###----------------------TERMINATION CRITERION----------------------###\n",
    "    if set(updated_primary_list) == set(primary_facilities_idx):\n",
    "        print(f'FINAL BEST PRIMARY FACILITIES : {updated_primary_list}')\n",
    "        for s, path in all_shortest_paths.items():\n",
    "            print(f\"Shortest path to {s}: {path} and cost : {shortest_distances[s]}\")\n",
    "        break\n",
    "    \n",
    "    ###----------------------ELSE CONTINUE TILL WHILE LOOP TERMINATES----------------------###\n",
    "    else:\n",
    "        primary_facilities_idx = list(updated_primary_list)\n",
    "        counter += 1\n",
    "        print(f'COUNTER : {counter}')\n",
    "        print(f'CURRENT BEST PRIMARY FACILITIES : {primary_facilities_idx}')\n",
    "        updated_primary_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
